{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2d395417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader,Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1fe12a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRFLayer(nn.Module):\n",
    "    def __init__(self, n_tags, n_features):\n",
    "        super().__init__()\n",
    "        self.n_tags = n_tags\n",
    "        self.n_features = n_features\n",
    "        # 定义模型参数\n",
    "        self.transitions = nn.Parameter(torch.empty(n_tags, n_tags))\n",
    "        self.emission_weight = nn.Parameter(torch.empty(n_features, n_tags))\n",
    "        self.start_transitions = nn.Parameter(torch.empty(n_tags))\n",
    "        self.end_transitions = nn.Parameter(torch.empty(n_tags))\n",
    "        self.reset_parameters()\n",
    "        # 调试信息\n",
    "        print(f\"CRFLayer初始化: n_tags={n_tags}, n_features={n_features}\")\n",
    "        print(f\"transitions shape: {self.transitions.shape}\")\n",
    "        \n",
    "    # 使用（-0.1,0.1）之间的均匀分布初始化参数\n",
    "    def reset_parameters(self):\n",
    "        nn.init.uniform_(self.transitions, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.emission_weight, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.start_transitions, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.end_transitions, -0.1, 0.1)\n",
    "    \n",
    "    # 使用动态规划计算得分\n",
    "    def compute_score(self, emissions, tags, masks):\n",
    "        seq_len, batch_size, n_tags = emissions.shape\n",
    "        # 调试信息\n",
    "        print(f\"compute_score: emissions.shape={emissions.shape}, tags.shape={tags.shape}\")\n",
    "        print(f\"transitions.shape={self.transitions.shape}, n_tags={n_tags}\")\n",
    "        # 确保所有标签索引在有效范围内\n",
    "        clamped_tags = torch.clamp(tags, 0, self.n_tags - 1)\n",
    "        \n",
    "        # 处理起始转移分数\n",
    "        start_indices = torch.clamp(clamped_tags[0], 0, self.start_transitions.size(0) - 1)\n",
    "        score = self.start_transitions[start_indices] + \\\n",
    "            emissions[0, torch.arange(batch_size), start_indices]\n",
    "        \n",
    "        for i in range(1, seq_len):\n",
    "            # 确保转移矩阵的索引在有效范围内\n",
    "            prev_tags = torch.clamp(clamped_tags[i-1], 0, self.transitions.size(0) - 1)\n",
    "            curr_tags = torch.clamp(clamped_tags[i], 0, self.transitions.size(1) - 1)\n",
    "            \n",
    "            # 确保批次索引在有效范围内\n",
    "            batch_indices = torch.clamp(torch.arange(batch_size), 0, emissions.size(1) - 1)\n",
    "            \n",
    "            score += self.transitions[prev_tags, curr_tags] * masks[i]\n",
    "            score += emissions[i, batch_indices, curr_tags] * masks[i]\n",
    "        \n",
    "        # 处理结束转移分数\n",
    "        seq_ends = masks.long().sum(dim=0) - 1\n",
    "        seq_ends = torch.clamp(seq_ends, 0, seq_len - 1)\n",
    "        batch_indices = torch.clamp(torch.arange(batch_size), 0, clamped_tags.size(1) - 1)\n",
    "        last_tags = clamped_tags[seq_ends, batch_indices]\n",
    "        last_tags = torch.clamp(last_tags, 0, self.end_transitions.size(0) - 1)\n",
    "        score += self.end_transitions[last_tags]\n",
    "        return score\n",
    "    \n",
    "    # 计算配分函数\n",
    "    def computer_normalizer(self, emissions, masks):\n",
    "        seq_len, batch_size, n_tags = emissions.shape\n",
    "        # 确保起始转移索引在有效范围内\n",
    "        start_indices = torch.clamp(torch.arange(min(n_tags, self.start_transitions.size(0))), 0, self.start_transitions.size(0) - 1)\n",
    "        start_trans = self.start_transitions[start_indices]\n",
    "        score = start_trans + emissions[0]\n",
    "        \n",
    "        for i in range(1, seq_len):\n",
    "            # batch_size * n_tags * 1 [y_{i-1}为某tag的总分]\n",
    "            broadcast_score = score.unsqueeze(2)\n",
    "            # batch_size * 1 * n_tags [y_i为某标签的发射分数]\n",
    "            broadcast_emissions = emissions[i].unsqueeze(1)\n",
    "            # batch_size * n_tags * n_tags [任意y_{i-1}到y_i的总分]\n",
    "            next_score = broadcast_score + self.transitions + broadcast_emissions\n",
    "            # batch_size * n_tags [对y_{i-1}求和]\n",
    "            next_score = torch.logsumexp(next_score, dim=1)\n",
    "            # masks为True则更新，否则保留\n",
    "            score = torch.where(masks[i].unsqueeze(1), next_score, score)\n",
    "            \n",
    "        # 确保结束转移索引在有效范围内\n",
    "        end_indices = torch.clamp(torch.arange(min(n_tags, self.end_transitions.size(0))), 0, self.end_transitions.size(0) - 1)\n",
    "        end_trans = self.end_transitions[end_indices]\n",
    "        score += end_trans\n",
    "        return torch.logsumexp(score, dim=1)\n",
    "    \n",
    "    def forward(self, features, tags, masks):\n",
    "        \"\"\"\n",
    "        features: seq_len * batch_size * n_features\n",
    "        tags/masks: seq_len * batch_size\n",
    "        \"\"\"\n",
    "        _, batch_size, _ = features.size()\n",
    "        emissions = torch.matmul(features, self.emission_weight)\n",
    "        masks = masks.to(torch.bool)\n",
    "        \n",
    "        # 确保标签索引在模型定义的范围内\n",
    "        tags = torch.clamp(tags, 0, self.n_tags - 1)\n",
    "        \n",
    "        score = self.compute_score(emissions, tags, masks)\n",
    "        partition = self.computer_normalizer(emissions, masks)\n",
    "        \n",
    "        likelihood = score - partition\n",
    "        return likelihood.sum() / batch_size\n",
    "    \n",
    "    def decode(self, features, masks):\n",
    "        # 与computer_normalizer类似，sum变为max\n",
    "        emissions = torch.matmul(features, self.emission_weight)\n",
    "        masks = masks.to(torch.bool)\n",
    "        \n",
    "        seq_len, batch_size, n_tags = emissions.shape\n",
    "        \n",
    "        # 确保起始转移索引在有效范围内\n",
    "        start_indices = torch.clamp(torch.arange(min(n_tags, self.start_transitions.size(0))), 0, self.start_transitions.size(0) - 1)\n",
    "        start_trans = self.start_transitions[start_indices]\n",
    "        score = start_trans + emissions[0]\n",
    "        history = []\n",
    "        \n",
    "        for i in range(1, seq_len):\n",
    "            broadcast_score = score.unsqueeze(2)\n",
    "            broadcast_emission = emissions[i].unsqueeze(1)\n",
    "            \n",
    "            next_score = broadcast_score + self.transitions + broadcast_emission\n",
    "            next_score, indices = next_score.max(dim=1)\n",
    "            \n",
    "            score = torch.where(masks[i].unsqueeze(1), next_score, score)\n",
    "            history.append(indices)\n",
    "            \n",
    "        # 确保结束转移索引在有效范围内\n",
    "        end_indices = torch.clamp(torch.arange(min(n_tags, self.end_transitions.size(0))), 0, self.end_transitions.size(0) - 1)\n",
    "        end_trans = self.end_transitions[end_indices]\n",
    "        score += end_trans\n",
    "        \n",
    "        seq_ends = masks.long().sum(dim=0) - 1\n",
    "        best_tags_list = []\n",
    "        \n",
    "        for idx in range(batch_size):\n",
    "            _, best_last_tag = score[idx].max(dim=0)\n",
    "            best_tags = [best_last_tag.item()]\n",
    "            \n",
    "            for hist in reversed(history[:seq_ends[idx]]):\n",
    "                best_last_tag = hist[idx][best_tags[-1]]\n",
    "                best_tags.append(best_last_tag.item())\n",
    "                \n",
    "            best_tags.reverse()\n",
    "            best_tags_list.append(best_tags)\n",
    "            \n",
    "        return best_tags_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "766487eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_CRF(nn.Module):\n",
    "    def __init__(self,vocab_size,hidden_size,num_layers,dropout,n_tags):\n",
    "        \"\"\"\n",
    "        参数介绍\n",
    "        vocab_size: 词表大小\n",
    "        hidden_size: 隐藏层大小\n",
    "        num_layers: LSTM层数\n",
    "        dropout: dropout概率\n",
    "        n_tags: 标签数量\n",
    "        \"\"\"\n",
    "        super(LSTM_CRF, self).__init__()\n",
    "        #define embedding\n",
    "        self.embedding=nn.Embedding(vocab_size,hidden_size)\n",
    "        #define LSTM\n",
    "        self.lstm=nn.LSTM(hidden_size=hidden_size,num_layers=num_layers,input_size=hidden_size,dropout=dropout,batch_first=False,bidirectional=True)\n",
    "        self.crf=CRFLayer(n_tags=n_tags,n_features=hidden_size*2)\n",
    "    def forward(self,input_ids,masks,labels):\n",
    "        \"\"\"\n",
    "        参数解释\n",
    "        input_ids:输入的id shaperge [batch_size,seq_len]\n",
    "        masks:输入的mask\n",
    "        labels:标签\n",
    "        \"\"\"\n",
    "        seq_len=min(input_ids.size(1),masks.size(1),labels.size(1))\n",
    "        input_ids = input_ids[:, :seq_len]\n",
    "        masks = masks[:, :seq_len]\n",
    "        labels = labels[:, :seq_len]\n",
    "        embed=self.embedding(input_ids)\n",
    "        embed=torch.transpose(embed,0,1)\n",
    "        masks=torch.transpose(masks,0,1)\n",
    "        labels=torch.transpose(labels,0,1)\n",
    "        hidden_states,_=self.lstm(embed)\n",
    "        llh=self.crf(hidden_states,labels,masks)\n",
    "        return llh\n",
    "    def decode(self,input_ids,masks):\n",
    "        embed=self.embedding(input_ids)\n",
    "        embed=torch.transpose(embed,0,1)\n",
    "        masks=torch.transpose(masks,0,1)\n",
    "        hidden_states,_=self.lstm(embed)\n",
    "        return self.crf.decode(hidden_states,masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b8084c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#准备测试数据\n",
    "class NerDataset(Dataset):\n",
    "    def __init__(self,sentences,labels,word_to_idx,tag_to_idx):\n",
    "        self.sentences=sentences\n",
    "        self.labels=labels\n",
    "        self.word_to_idx=word_to_idx\n",
    "        self.tag_to_idx=tag_to_idx\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    # 在数据预处理时确保标签索引正确\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.sentences[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # 将单词转换为索引\n",
    "        sent_ids = [self.word_to_idx.get(word, 0) for word in sentence]\n",
    "        # 确保标签索引在有效范围内\n",
    "        label_ids = [self.tag_to_idx.get(tag, 0) for tag in label]\n",
    "        \n",
    "        # 创建mask\n",
    "        mask = [1] * len(sent_ids)\n",
    "        \n",
    "        return (torch.tensor(sent_ids, dtype=torch.long), \n",
    "                torch.tensor(label_ids, dtype=torch.long), \n",
    "                torch.tensor(mask, dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "019bc40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例数据\n",
    "training_data = [\n",
    "    (\"the wall street journal reported today that apple corporation made money\".split(),\n",
    "     \"B I I I O O O B I O\".split()),\n",
    "    (\"georgia tech is a university in georgia\".split(),\n",
    "     \"B I O O O O B\".split()),\n",
    "    (\"the cpu speed is very fast\".split(),\n",
    "     \"O O O O O O\".split()),\n",
    "    (\"microsoft is located in washington\".split(),\n",
    "     \"B O O O B\".split())\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ec26429c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词汇表大小: 25\n",
      "标签表: {'B': 0, 'I': 1, 'O': 2}\n",
      "标签数量: 3\n"
     ]
    }
   ],
   "source": [
    "#进行简单的数据处理\n",
    "word_to_idx={'<UNK>':0}\n",
    "tag_to_idx={'B':0,'I':1,'O':2}\n",
    "for sentence ,tags in training_data:\n",
    "    for word in sentence:\n",
    "        if word not in word_to_idx:\n",
    "            word_to_idx[word]=len(word_to_idx)\n",
    "    for tag in tags:\n",
    "        if tag not in tag_to_idx:\n",
    "            tag_to_idx[tag]=len(tag_to_idx)\n",
    "\n",
    "\n",
    "print(\"词汇表大小:\", len(word_to_idx))\n",
    "print(\"标签表:\", tag_to_idx)\n",
    "print(\"标签数量:\", len(tag_to_idx)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "155783ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建数据集\n",
    "dataset=NerDataset(\n",
    "    [s[0] for s in training_data],\n",
    "    [s[1] for s in training_data],\n",
    "    word_to_idx=word_to_idx,\n",
    "    tag_to_idx=tag_to_idx\n",
    ")\n",
    "batch_size=1\n",
    "train_data_loader=DataLoader(dataset,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ea00e6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "#设置模型参数\n",
    "vocab_size=len(word_to_idx)\n",
    "hidden_size=128\n",
    "num_layers=1\n",
    "dropout=0.1\n",
    "n_tags=len(tag_to_idx)\n",
    "print(n_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6c078499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRFLayer初始化: n_tags=3, n_features=256\n",
      "transitions shape: torch.Size([3, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/app_for_code/miniconda3/envs/nlp/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "#初始化模型\n",
    "model=LSTM_CRF(\n",
    "    vocab_size=vocab_size,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout,\n",
    "    n_tags=n_tags\n",
    ")\n",
    "\n",
    "#定义优化器\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a5755f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "开始训练...\n",
      "compute_score: emissions.shape=torch.Size([7, 1, 3]), tags.shape=torch.Size([7, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([6, 1, 3]), tags.shape=torch.Size([6, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([10, 1, 3]), tags.shape=torch.Size([10, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([5, 1, 3]), tags.shape=torch.Size([5, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "Epoch 0, Average Loss: -7.062752366065979\n",
      "compute_score: emissions.shape=torch.Size([7, 1, 3]), tags.shape=torch.Size([7, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([6, 1, 3]), tags.shape=torch.Size([6, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([10, 1, 3]), tags.shape=torch.Size([10, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([5, 1, 3]), tags.shape=torch.Size([5, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([10, 1, 3]), tags.shape=torch.Size([10, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([6, 1, 3]), tags.shape=torch.Size([6, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([5, 1, 3]), tags.shape=torch.Size([5, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([7, 1, 3]), tags.shape=torch.Size([7, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([10, 1, 3]), tags.shape=torch.Size([10, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([6, 1, 3]), tags.shape=torch.Size([6, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([7, 1, 3]), tags.shape=torch.Size([7, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([5, 1, 3]), tags.shape=torch.Size([5, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([10, 1, 3]), tags.shape=torch.Size([10, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([7, 1, 3]), tags.shape=torch.Size([7, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([6, 1, 3]), tags.shape=torch.Size([6, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([5, 1, 3]), tags.shape=torch.Size([5, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([7, 1, 3]), tags.shape=torch.Size([7, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([5, 1, 3]), tags.shape=torch.Size([5, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([10, 1, 3]), tags.shape=torch.Size([10, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([6, 1, 3]), tags.shape=torch.Size([6, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([6, 1, 3]), tags.shape=torch.Size([6, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([7, 1, 3]), tags.shape=torch.Size([7, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([10, 1, 3]), tags.shape=torch.Size([10, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([5, 1, 3]), tags.shape=torch.Size([5, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([6, 1, 3]), tags.shape=torch.Size([6, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([5, 1, 3]), tags.shape=torch.Size([5, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([7, 1, 3]), tags.shape=torch.Size([7, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([10, 1, 3]), tags.shape=torch.Size([10, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([5, 1, 3]), tags.shape=torch.Size([5, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([6, 1, 3]), tags.shape=torch.Size([6, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([7, 1, 3]), tags.shape=torch.Size([7, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([10, 1, 3]), tags.shape=torch.Size([10, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([5, 1, 3]), tags.shape=torch.Size([5, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([10, 1, 3]), tags.shape=torch.Size([10, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([6, 1, 3]), tags.shape=torch.Size([6, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([7, 1, 3]), tags.shape=torch.Size([7, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([6, 1, 3]), tags.shape=torch.Size([6, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([7, 1, 3]), tags.shape=torch.Size([7, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([10, 1, 3]), tags.shape=torch.Size([10, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([5, 1, 3]), tags.shape=torch.Size([5, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "Epoch 10, Average Loss: -0.0010499954223632812\n",
      "compute_score: emissions.shape=torch.Size([6, 1, 3]), tags.shape=torch.Size([6, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([10, 1, 3]), tags.shape=torch.Size([10, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([7, 1, 3]), tags.shape=torch.Size([7, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([5, 1, 3]), tags.shape=torch.Size([5, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([7, 1, 3]), tags.shape=torch.Size([7, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([5, 1, 3]), tags.shape=torch.Size([5, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([6, 1, 3]), tags.shape=torch.Size([6, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([10, 1, 3]), tags.shape=torch.Size([10, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([6, 1, 3]), tags.shape=torch.Size([6, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([5, 1, 3]), tags.shape=torch.Size([5, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([7, 1, 3]), tags.shape=torch.Size([7, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([10, 1, 3]), tags.shape=torch.Size([10, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([7, 1, 3]), tags.shape=torch.Size([7, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([6, 1, 3]), tags.shape=torch.Size([6, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([5, 1, 3]), tags.shape=torch.Size([5, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([10, 1, 3]), tags.shape=torch.Size([10, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([5, 1, 3]), tags.shape=torch.Size([5, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([7, 1, 3]), tags.shape=torch.Size([7, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([6, 1, 3]), tags.shape=torch.Size([6, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([10, 1, 3]), tags.shape=torch.Size([10, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([5, 1, 3]), tags.shape=torch.Size([5, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([6, 1, 3]), tags.shape=torch.Size([6, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([10, 1, 3]), tags.shape=torch.Size([10, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([7, 1, 3]), tags.shape=torch.Size([7, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([7, 1, 3]), tags.shape=torch.Size([7, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([10, 1, 3]), tags.shape=torch.Size([10, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([6, 1, 3]), tags.shape=torch.Size([6, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([5, 1, 3]), tags.shape=torch.Size([5, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([6, 1, 3]), tags.shape=torch.Size([6, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([7, 1, 3]), tags.shape=torch.Size([7, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([10, 1, 3]), tags.shape=torch.Size([10, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([5, 1, 3]), tags.shape=torch.Size([5, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([10, 1, 3]), tags.shape=torch.Size([10, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([7, 1, 3]), tags.shape=torch.Size([7, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([6, 1, 3]), tags.shape=torch.Size([6, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([5, 1, 3]), tags.shape=torch.Size([5, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([6, 1, 3]), tags.shape=torch.Size([6, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([7, 1, 3]), tags.shape=torch.Size([7, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([10, 1, 3]), tags.shape=torch.Size([10, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([5, 1, 3]), tags.shape=torch.Size([5, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "Epoch 20, Average Loss: -0.0005970001220703125\n",
      "compute_score: emissions.shape=torch.Size([7, 1, 3]), tags.shape=torch.Size([7, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([5, 1, 3]), tags.shape=torch.Size([5, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([6, 1, 3]), tags.shape=torch.Size([6, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([10, 1, 3]), tags.shape=torch.Size([10, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([7, 1, 3]), tags.shape=torch.Size([7, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([5, 1, 3]), tags.shape=torch.Size([5, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([6, 1, 3]), tags.shape=torch.Size([6, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([10, 1, 3]), tags.shape=torch.Size([10, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([5, 1, 3]), tags.shape=torch.Size([5, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([10, 1, 3]), tags.shape=torch.Size([10, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([6, 1, 3]), tags.shape=torch.Size([6, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([7, 1, 3]), tags.shape=torch.Size([7, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([7, 1, 3]), tags.shape=torch.Size([7, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([10, 1, 3]), tags.shape=torch.Size([10, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([6, 1, 3]), tags.shape=torch.Size([6, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([5, 1, 3]), tags.shape=torch.Size([5, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([10, 1, 3]), tags.shape=torch.Size([10, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([7, 1, 3]), tags.shape=torch.Size([7, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([6, 1, 3]), tags.shape=torch.Size([6, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([5, 1, 3]), tags.shape=torch.Size([5, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([7, 1, 3]), tags.shape=torch.Size([7, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([10, 1, 3]), tags.shape=torch.Size([10, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([6, 1, 3]), tags.shape=torch.Size([6, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([5, 1, 3]), tags.shape=torch.Size([5, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([10, 1, 3]), tags.shape=torch.Size([10, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([5, 1, 3]), tags.shape=torch.Size([5, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([7, 1, 3]), tags.shape=torch.Size([7, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([6, 1, 3]), tags.shape=torch.Size([6, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([5, 1, 3]), tags.shape=torch.Size([5, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([10, 1, 3]), tags.shape=torch.Size([10, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([6, 1, 3]), tags.shape=torch.Size([6, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([7, 1, 3]), tags.shape=torch.Size([7, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([7, 1, 3]), tags.shape=torch.Size([7, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([5, 1, 3]), tags.shape=torch.Size([5, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([6, 1, 3]), tags.shape=torch.Size([6, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "compute_score: emissions.shape=torch.Size([10, 1, 3]), tags.shape=torch.Size([10, 1])\n",
      "transitions.shape=torch.Size([3, 3]), n_tags=3\n",
      "训练完成!\n"
     ]
    }
   ],
   "source": [
    "#开始训练模型\n",
    "print(\"\\n开始训练...\")\n",
    "model.train()\n",
    "for epoch in range(30):\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    for batch_idx, batch in enumerate(train_data_loader):\n",
    "        input_ids, labels, masks = batch\n",
    "        \n",
    "        # 确保标签在有效范围内\n",
    "        labels = torch.clamp(labels, 0, n_tags - 1)\n",
    "        \n",
    "        try:\n",
    "            loss = model(input_ids, masks, labels)\n",
    "            optimizer.zero_grad()\n",
    "            (-loss).backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Batch {batch_idx} 出错: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if epoch % 10 == 0 and num_batches > 0:\n",
    "        print(f\"Epoch {epoch}, Average Loss: {total_loss/num_batches}\")\n",
    "\n",
    "print(\"训练完成!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "59fec86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "模型预测结果:\n",
      "输入句子: the wall street journal reported today\n",
      "预测标签: [0, 1, 1, 1, 2, 2]\n",
      "标签名称: ['B', 'I', 'I', 'I', 'O', 'O']\n",
      "--------------------------------------------------\n",
      "输入句子: georgia tech is a university\n",
      "预测标签: [0, 1, 2, 2, 2]\n",
      "标签名称: ['B', 'I', 'O', 'O', 'O']\n",
      "--------------------------------------------------\n",
      "模型参数:\n",
      "词汇表大小: 25\n",
      "隐藏层大小: 128\n",
      "LSTM层数: 1\n",
      "标签数量: 3\n",
      "词汇表: ['<UNK>', 'the', 'wall', 'street', 'journal', 'reported', 'today', 'that', 'apple', 'corporation']...\n",
      "标签表: ['B', 'I', 'O']\n"
     ]
    }
   ],
   "source": [
    "# 测试模型\n",
    "model.eval()\n",
    "test_sentences = [\n",
    "    \"the wall street journal reported today\".split(),\n",
    "    \"georgia tech is a university\".split()\n",
    "]\n",
    "\n",
    "print(\"\\n模型预测结果:\")\n",
    "with torch.no_grad():\n",
    "    for sentence in test_sentences:\n",
    "        # 将句子转换为索引\n",
    "        sent_ids = torch.tensor([[word_to_idx.get(word, 0) for word in sentence]])\n",
    "        masks = torch.tensor([[1] * len(sentence)])\n",
    "        \n",
    "        # 获取预测结果\n",
    "        predictions = model.decode(sent_ids, masks)\n",
    "        \n",
    "        print(f\"输入句子: {' '.join(sentence)}\")\n",
    "        print(f\"预测标签: {predictions[0]}\")\n",
    "        \n",
    "        # 将标签索引转换为标签名称\n",
    "        tag_names = list(tag_to_idx.keys())\n",
    "        pred_tags = [tag_names[idx] for idx in predictions[0]]\n",
    "        print(f\"标签名称: {pred_tags}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# 展示模型参数\n",
    "print(f\"模型参数:\")\n",
    "print(f\"词汇表大小: {vocab_size}\")\n",
    "print(f\"隐藏层大小: {hidden_size}\")\n",
    "print(f\"LSTM层数: {num_layers}\")\n",
    "print(f\"标签数量: {n_tags}\")\n",
    "print(f\"词汇表: {list(word_to_idx.keys())[:10]}...\")  # 显示前10个词汇\n",
    "print(f\"标签表: {list(tag_to_idx.keys())}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
