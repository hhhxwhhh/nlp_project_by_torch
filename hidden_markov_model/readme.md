# 隐马尔可夫模型(HMM)矩阵详解

## 1. 模型参数矩阵

### 1.1 状态转移概率矩阵 A

**形状**: (N, N)，其中 N 是隐藏状态数量

**含义**: A[i][j] 表示在时刻 t 处于状态 i 的条件下，在时刻 t+1 转移到状态 j 的概率

**数学表示**: aᵢⱼ = P(qₜ₊₁ = j | qₜ = i)

**作用**:

- 描述隐藏状态之间的转移规律
- 决定模型的状态演化过程
- 是 HMM 的核心动态特性描述

**示例**（天气模型）:
Sunny Rainy
0.5 0.5

### 1.2 观测概率矩阵 B

**形状**: (N, M)，其中 N 是隐藏状态数量，M 是观测状态数量

**含义**: B[i][k] 表示在状态 i 下观测到符号 k 的概率

**数学表示**: bᵢ(k) = P(oₜ = k | qₜ = i)

**作用**:

- 描述隐藏状态与观测状态之间的关系
- 决定在特定状态下产生特定观测的概率
- 连接隐藏状态与可观测世界

**示例**（天气模型）:
walk shop clean
0.5 0.2 0.3

### 1.3 初始状态概率向量 π

**形状**: (N,)，其中 N 是隐藏状态数量

**含义**: π[i] 表示在初始时刻 t=1 处于状态 i 的概率

**数学表示**: πᵢ = P(q₁ = i)

**作用**:

- 描述序列开始时各状态的概率分布
- 决定模型的初始状态选择
- 影响整个序列的状态演化起点

**示例**:

## 2. 算法计算矩阵

### 2.1 前向概率矩阵 α (alpha)

**形状**: (T, N)，其中 T 是观测序列长度，N 是隐藏状态数量

**含义**: α[t][i] 表示在时刻 t 处于状态 i 且观测到序列 o₁,o₂,...,oₜ 的联合概率

**数学表示**: αₜ(i) = P(o₁,o₂,...,oₜ, qₜ = i | λ)

**作用**:

- 解决评估问题：计算给定观测序列的概率
- 作为其他算法的基础计算工具
- 提供序列概率的递归计算方法

**计算公式**:

- 初始化: α₁(i) = πᵢ × bᵢ(o₁)
- 递归: αₜ₊₁(j) = [Σᵢ αₜ(i) × aᵢⱼ] × bⱼ(oₜ₊₁)

### 2.2 后向概率矩阵 β (beta)

**形状**: (T, N)，其中 T 是观测序列长度，N 是隐藏状态数量

**含义**: β[t][i] 表示在时刻 t 处于状态 i 的条件下，从时刻 t+1 到 T 观测到序列 oₜ₊₁,oₜ₊₂,...,oₜ 的条件概率

**数学表示**: βₜ(i) = P(oₜ₊₁,oₜ₊₂,...,oₜ | qₜ = i, λ)

**作用**:

- 与前向概率配合使用进行各种概率计算
- 在 Baum-Welch 算法中计算统计量
- 提供从后向前的递归计算方法

**计算公式**:

- 初始化: βₜ(i) = 1
- 递归: βₜ(i) = Σⱼ aᵢⱼ × bⱼ(oₜ₊₁) × βₜ₊₁(j)

### 2.3 维特比概率矩阵 δ (delta)

**形状**: (T, N)，其中 T 是观测序列长度，N 是隐藏状态数量

**含义**: δ[t][i] 表示在时刻 t 处于状态 i 且观测到序列 o₁,o₂,...,oₜ 的最优路径的概率

**数学表示**: δₜ(i) = max\_{q₁,...,qₜ₋₁} P(q₁,...,qₜ₋₁, qₜ = i, o₁,...,oₜ | λ)

**作用**:

- 解决解码问题：找出最可能的隐藏状态序列
- 通过动态规划找到最优路径
- 记录到达每个状态的最大概率

**计算公式**:

- 初始化: δ₁(i) = πᵢ × bᵢ(o₁)
- 递归: δₜ₊₁(j) = maxᵢ[δₜ(i) × aᵢⱼ] × bⱼ(oₜ₊₁)

### 2.4 路径记录矩阵 ψ (psi)

**形状**: (T, N)，其中 T 是观测序列长度，N 是隐藏状态数量

**含义**: ψ[t][i] 记录在时刻 t 处于状态 i 时，时刻 t-1 的最优前驱状态

**作用**:

- 辅助维特比算法进行路径回溯
- 记录最优决策路径
- 重构最优状态序列

**计算公式**:

- ψₜ₊₁(j) = argmaxᵢ[δₜ(i) × aᵢⱼ]

## 3. 学习算法统计矩阵

### 3.1 状态转移统计矩阵 ξ (xi)

**形状**: (T-1, N, N) 或累积 (N, N)

**含义**: ξ[t][i][j] 表示在给定模型和观测序列下，时刻 t 处于状态 i 且时刻 t+1 处于状态 j 的概率

**数学表示**: ξₜ(i,j) = P(qₜ = i, qₜ₊₁ = j | O, λ)

**作用**:

- Baum-Welch 算法中用于更新状态转移概率矩阵 A
- 统计状态转移的期望频次
- 提供参数学习的统计基础

**计算公式**:

- ξₜ(i,j) = αₜ(i) × aᵢⱼ × bⱼ(oₜ₊₁) × βₜ₊₁(j) / ΣᵢΣⱼ αₜ(i) × aᵢⱼ × bⱼ(oₜ₊₁) × βₜ₊₁(j)

### 3.2 状态概率统计矩阵 γ (gamma)

**形状**: (T, N) 或累积统计 (N, M)

**含义**: γ[t][i] 表示在给定模型和观测序列下，时刻 t 处于状态 i 的概率

**数学表示**: γₜ(i) = P(qₜ = i | O, λ)

**作用**:

- Baum-Welch 算法中用于更新初始状态概率 π 和观测概率矩阵 B
- 统计各状态的期望出现频次
- 提供观测概率更新的统计基础

**计算公式**:

- γₜ(i) = αₜ(i) × βₜ(i) / Σᵢ αₜ(i) × βₜ(i)

### 3.3 初始状态统计向量

**形状**: (N,)

**含义**: 累积统计每个训练序列在时刻 1 处于各状态的概率

**作用**:

- Baum-Welch 算法中用于更新初始状态概率向量 π
- 统计初始状态的期望分布
- 提供模型初始化参数的学习基础

## 4. 矩阵关系与应用

### 4.1 HMM 的三个基本问题

1. **评估问题** (Evaluation)

   - 使用 α 矩阵计算观测序列概率
   - P(O | λ) = Σᵢ αₜ(i)

2. **解码问题** (Decoding)

   - 使用 δ 和 ψ 矩阵找出最优状态序列
   - P\* = maxₜ δₜ(i)
   - 回溯路径: q\* = ψₜ(i)

3. **学习问题** (Learning)
   - 使用 ξ、γ 等统计矩阵通过 Baum-Welch 算法学习模型参数
   - aᵢⱼ = Σₜξₜ(i,j) / Σₜγₜ(i)
   - bⱼ(k) = Σₜ,ₒₜ=ᵥγₜ(j) / Σₜγₜ(j)
   - πᵢ = γ₁(i)

### 4.2 矩阵间的数学关系

- **前向-后向关系**: γₜ(i) = αₜ(i) × βₜ(i) / Σᵢ αₜ(i) × βₜ(i)
- **状态转移统计**: ξₜ(i,j) = αₜ(i) × aᵢⱼ × bⱼ(oₜ₊₁) × βₜ₊₁(j) / P(O | λ)
- **观测概率统计**: γₜ(i) 用于统计在状态 i 下产生各种观测的频次

这些矩阵构成了隐马尔可夫模型完整的数学框架，使得我们能够有效地进行序列建模、预测和学习。
